# Deployment Strategy - Two Platform Focus
## Jetson Nano (DL) + Arduino Uno (ML)

**Date:** 2025-12-15
**Strategy:** Focus on two platforms with clear use cases
**Status:** Ready to implement

---

## Platform Strategy

### **Deep Learning â†’ Jetson Nano**
**Hardware:** NVIDIA Jetson Nano Developer Kit ($99)
**Use Case:** TimesNet inference for complex time-series analysis
**Models:** Deep Learning (TimesNet, LSTM, CNN-based)

### **Classical ML â†’ Arduino Uno**
**Hardware:** Arduino Uno Rev3 ($27)
**Use Case:** Decision Trees/Random Forest for simple classification
**Models:** Classical ML (Decision Tree, Random Forest, SVM)

---

## Why This Makes Sense

### **Jetson Nano for Deep Learning:**

âœ… **Technical Fit:**
- GPU: 128 CUDA cores (Maxwell architecture)
- RAM: 4GB LPDDR4
- CPU: Quad-core ARM A57 @ 1.43 GHz
- Can run TensorRT (NVIDIA's optimized inference)
- Supports ONNX models natively

âœ… **TimesNet Requirements:**
- Needs floating-point operations (lots of them)
- Benefits from GPU acceleration
- Model size: ~50K-500K parameters
- Jetson can handle this easily

âœ… **User Experience:**
- Deploy via SSH/SCP
- Python-based inference (easy)
- Can use systemd for auto-start
- Web dashboard for monitoring

**Example Use Case:**
```
Fall Detection System (TimesNet)
- Sensor: IMU on Jetson carrier board
- Processing: TimesNet inference at 20 FPS
- Action: Alert via WiFi/Bluetooth
- Power: 5W (with GPU throttled)
```

---

### **Arduino Uno for Classical ML:**

âœ… **Technical Fit:**
- MCU: ATmega328P @ 16 MHz
- RAM: 2KB SRAM (yes, 2KB!)
- Flash: 32KB program storage
- Perfect for decision trees (small footprint)

âœ… **Classical ML Requirements:**
- Decision tree: Just if-else statements in C
- Random Forest: Multiple trees, still lightweight
- Model size: Few hundred bytes to few KB
- Arduino has plenty of space

âœ… **User Experience:**
- Deploy via Arduino IDE (familiar to makers)
- Upload sketch via USB
- Standalone operation (no network needed)
- Ultra-low power (~20mA)

**Example Use Case:**
```
Gesture Recognition (Decision Tree)
- Sensor: MPU6050 accelerometer
- Processing: Decision tree (50 nodes)
- Action: Control servo motor
- Power: 50mA total (battery-powered for months)
```

---

## Implementation Plan

### **Path 1: Jetson Nano Deployment (C++ Pipeline Builder)**

**Use the C++ standalone tool** from previous plan:
- Visual pipeline editor (imgui-node-editor)
- Drag sensors â†’ TimesNet â†’ outputs
- Generate deployment package

**What Gets Generated:**

```
jetson_fall_detection/
â”œâ”€â”€ deploy.sh                    # Auto-deploy script
â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ model.onnx              # Your TimesNet model
â”‚   â”œâ”€â”€ model.trt               # TensorRT engine (generated)
â”‚   â”œâ”€â”€ inference.py            # Python inference script
â”‚   â””â”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ sensors/
â”‚   â”œâ”€â”€ mpu6050_reader.py       # Sensor interface
â”‚   â””â”€â”€ sensor_config.yaml      # I2C config
â”œâ”€â”€ systemd/
â”‚   â””â”€â”€ fall_detection.service  # Auto-start service
â””â”€â”€ README.md                    # Setup instructions
```

**Deployment Steps:**
```bash
# 1. Copy to Jetson
scp -r jetson_fall_detection/ nvidia@jetson.local:~/

# 2. SSH into Jetson
ssh nvidia@jetson.local

# 3. Run deploy script
cd jetson_fall_detection
./deploy.sh

# 4. Service starts automatically
systemctl status fall_detection
```

**Code Example (inference.py):**
```python
import tensorrt as trt
import numpy as np
from sensor_reader import MPU6050Reader

# Load TensorRT engine
engine = load_trt_engine("model.trt")

# Sensor setup
sensor = MPU6050Reader(i2c_addr=0x68, sample_rate=100)

# Inference loop
while True:
    # Read 100 samples (window)
    window = sensor.read_window(100)

    # Normalize
    window_norm = (window - mean) / std

    # Run inference
    prediction = engine.infer(window_norm)

    # Take action
    if prediction == 1:  # Fall detected
        trigger_alert()
```

---

### **Path 2: Arduino Deployment (Simple Code Generator)**

**No C++ pipeline builder needed** - just direct code generation!

**User Workflow:**
1. Train Decision Tree in Python app
2. Click "Export to Arduino"
3. Get `.ino` sketch file
4. Upload to Arduino via Arduino IDE

**What Gets Generated:**

```
gesture_recognition/
â””â”€â”€ gesture_recognition.ino     # Complete Arduino sketch
```

**Code Example (gesture_recognition.ino):**
```cpp
// Auto-generated by CiRA FutureEdge Studio
// Model: Decision Tree (50 nodes)
// Sensor: MPU6050

#include <Wire.h>
#include <MPU6050.h>

MPU6050 sensor;

// Decision tree structure (auto-generated)
int classify(float ax, float ay, float az) {
    // Tree generated from scikit-learn
    if (ax > 2.5) {
        if (ay < -1.2) {
            return 0;  // Gesture: Swipe Left
        } else {
            if (az > 9.0) {
                return 1;  // Gesture: Shake
            } else {
                return 2;  // Gesture: Tilt
            }
        }
    } else {
        // ... rest of tree
    }
}

void setup() {
    Serial.begin(9600);
    Wire.begin();
    sensor.initialize();
}

void loop() {
    // Read sensor
    int16_t ax, ay, az;
    sensor.getAcceleration(&ax, &ay, &az);

    // Convert to g's
    float ax_g = ax / 16384.0;
    float ay_g = ay / 16384.0;
    float az_g = az / 16384.0;

    // Classify
    int gesture = classify(ax_g, ay_g, az_g);

    // Output
    Serial.print("Gesture: ");
    Serial.println(gesture);

    delay(100);
}
```

---

## Updated File Structure

```
D:\CiRA FES\
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ model_panel.py              # DL tab
â”‚   â”‚   â””â”€ [Deploy to Jetson] â†’ Launches C++ pipeline builder
â”‚   â””â”€â”€ ml_panel.py                 # ML tab
â”‚       â””â”€ [Export to Arduino] â†’ Direct code generation
â”‚
â”œâ”€â”€ pipeline_builder/               # C++ standalone (for Jetson)
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ jetson/                 # Jetson-specific templates
â”‚   â”‚       â”œâ”€â”€ inference.py.jinja2
â”‚   â”‚       â”œâ”€â”€ deploy.sh.jinja2
â”‚   â”‚       â””â”€â”€ systemd.service.jinja2
â”‚   â””â”€â”€ CMakeLists.txt
â”‚
â””â”€â”€ core/
    â””â”€â”€ deployment/
        â”œâ”€â”€ jetson_generator.py     # Jetson package generator
        â””â”€â”€ arduino_generator.py    # Arduino sketch generator
```

---

## Implementation Phases (Updated)

### **Phase 1: Arduino Deployment (EASIEST - 1 week)**

**Why First:**
- âœ… Simpler (no C++ pipeline builder)
- âœ… Pure Python code generation
- âœ… Quick win for users
- âœ… Validates deployment workflow

**Deliverable:**
```python
# In ml_panel.py
def export_to_arduino(self, model):
    from core.deployment.arduino_generator import ArduinoGenerator

    generator = ArduinoGenerator(model, sensor="mpu6050")
    sketch_file = generator.generate()

    messagebox.showinfo(
        "Success",
        f"Arduino sketch generated!\n\n"
        f"File: {sketch_file}\n\n"
        f"Open in Arduino IDE and upload to your board."
    )
```

**Code Generator:**
```python
# core/deployment/arduino_generator.py
from sklearn.tree import DecisionTreeClassifier
import numpy as np

class ArduinoGenerator:
    def generate_decision_tree_code(self, tree):
        """Convert sklearn decision tree to C code."""

        def recurse(node_id, depth):
            indent = "    " * depth

            if tree.feature[node_id] != -2:  # Not a leaf
                feature = tree.feature[node_id]
                threshold = tree.threshold[node_id]

                code = f"{indent}if (features[{feature}] <= {threshold:.6f}) {{\n"
                code += recurse(tree.children_left[node_id], depth + 1)
                code += f"{indent}}} else {{\n"
                code += recurse(tree.children_right[node_id], depth + 1)
                code += f"{indent}}}\n"
                return code
            else:  # Leaf node
                class_id = np.argmax(tree.value[node_id][0])
                return f"{indent}return {class_id};\n"

        return recurse(0, 0)
```

---

### **Phase 2: Jetson Deployment (C++ Pipeline Builder - 4 weeks)**

**Use phased plan from CPP_PIPELINE_BUILDER_PHASED_IMPLEMENTATION.md**

But **only focus on Jetson templates:**
- Python inference scripts (not C++ firmware)
- TensorRT conversion
- Systemd services
- Deployment scripts

**Template Example:**
```python
# templates/jetson/inference.py.jinja2
import tensorrt as trt
import pycuda.driver as cuda
import numpy as np

class TimesNetInference:
    def __init__(self, engine_path):
        self.engine = self.load_engine(engine_path)

    def infer(self, input_data):
        # TensorRT inference
        {% for node in nodes %}
        {% if node.type == "TimesNet" %}
        # Run model: {{ node.config.model_file }}
        output = self.engine.infer(input_data)
        {% endif %}
        {% endfor %}
        return output
```

---

## User Workflows

### **Workflow 1: Deploy DL Model to Jetson**

```
1. User trains TimesNet in DL tab
2. Click [ðŸš€ Deploy to Jetson Nano]
3. C++ pipeline builder opens
4. Drag: IMU â†’ Normalize â†’ TimesNet â†’ Alert
5. Click "Generate Deployment Package"
6. Get: jetson_package.zip
7. Copy to Jetson and run deploy.sh
8. System running! âœ…
```

### **Workflow 2: Deploy ML Model to Arduino**

```
1. User trains Decision Tree in ML tab
2. Click [ðŸ“¤ Export to Arduino]
3. Dialog: "Select sensor" â†’ MPU6050
4. Get: gesture_recognition.ino
5. Open in Arduino IDE
6. Upload to Arduino Uno
7. System running! âœ…
```

---

## Hardware Setup Guides

### **Jetson Nano Setup:**

```markdown
# Jetson Nano Setup for CiRA Deployments

## 1. Initial Setup
- Flash JetPack 4.6.1 to SD card
- Boot Jetson, complete first-time setup
- Connect to WiFi/Ethernet

## 2. Install Dependencies
```bash
sudo apt update
sudo apt install python3-pip
pip3 install tensorrt pycuda numpy
```

## 3. Connect Sensors
- I2C: Pins 3 (SDA), 5 (SCL)
- Enable I2C: `sudo i2cdetect -y -r 1`

## 4. Deploy Your Model
```bash
# Copy deployment package
scp jetson_package.zip nvidia@jetson.local:~/

# SSH into Jetson
ssh nvidia@jetson.local
unzip jetson_package.zip
cd jetson_package
./deploy.sh
```

## 5. Monitor
```bash
# Check service status
systemctl status your_model

# View logs
journalctl -u your_model -f
```
```

### **Arduino Uno Setup:**

```markdown
# Arduino Uno Setup for CiRA Deployments

## 1. Install Arduino IDE
- Download from arduino.cc
- Install USB drivers

## 2. Connect Sensor (MPU6050)
- VCC â†’ 5V
- GND â†’ GND
- SDA â†’ A4
- SCL â†’ A5

## 3. Install Libraries
In Arduino IDE:
- Sketch â†’ Include Library â†’ Manage Libraries
- Search "MPU6050" â†’ Install

## 4. Upload Sketch
- File â†’ Open â†’ gesture_recognition.ino
- Tools â†’ Board â†’ Arduino Uno
- Tools â†’ Port â†’ (select your port)
- Upload âœ…

## 5. Test
- Tools â†’ Serial Monitor
- Baud rate: 9600
- Should see predictions!
```

---

## Updated Timeline

| Phase | Platform | Duration | Deliverable |
|-------|----------|----------|-------------|
| **Phase 1** | Arduino | 1 week | ML â†’ Arduino code generator |
| **Phase 2-5** | Jetson | 4 weeks | DL â†’ Jetson pipeline builder |

**Total: 5 weeks** to support both platforms completely

---

## Cost Analysis for Users

### **Jetson Nano Setup:**
- Jetson Nano Dev Kit: $99
- SD Card (64GB): $15
- Power Supply (5V 4A): $10
- MPU6050 Sensor: $3
- **Total: ~$127**

### **Arduino Uno Setup:**
- Arduino Uno R3: $27
- MPU6050 Sensor: $3
- USB Cable: $5
- **Total: ~$35**

**Value Proposition:**
- **Hobbyists/Students:** Arduino ($35) for learning
- **Serious Projects:** Jetson ($127) for production

---

## Marketing Angles

### **For Jetson:**
"Deploy your TimesNet models to NVIDIA Jetson Nano with one click. GPU-accelerated inference, production-ready deployment."

### **For Arduino:**
"Turn your ML models into Arduino sketches instantly. No coding required. Upload and run in 5 minutes."

---

**This is a much cleaner, focused strategy!**

**Should I:**
1. âœ… Update the C++ pipeline builder plan to focus ONLY on Jetson?
2. âœ… Create a simple Arduino code generator implementation plan?

Or are you ready to start with **Phase 1 (Arduino)** since it's the quickest win? ðŸš€
